import cv2
import json
import os
import torch
from ultralytics import YOLO

class PoseEstimator:
    def __init__(self, model_path='yolo11n-pose.pt'):
        """
        YOLO ëª¨ë¸ ì´ˆê¸°í™”
        :param model_path: ì‚¬ìš©í•  YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œë¨)
        """
        print(f"ğŸ”„ [AI] YOLO ëª¨ë¸ ë¡œë”© ì¤‘... ({model_path})")
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"âš¡ [AI] ì‹¤í–‰ ë””ë°”ì´ìŠ¤: {self.device}")
        
        self.model = YOLO(model_path)
        print("âœ… [AI] ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    def process_video(self, video_path, output_dir):
        """
        ì˜ìƒì„ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ì—¬ ìŠ¤ì¼ˆë ˆí†¤ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        """
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        video_name = os.path.splitext(os.path.basename(video_path))[0]
        output_json_path = os.path.join(output_dir, f"{video_name}_analysis.json")
        
        # ì˜ìƒ ì •ë³´ ì½ê¸°
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"ğŸ¬ [AI] ë¶„ì„ ì‹œì‘: {video_name} (FPS: {fps}, Frames: {total_frames})")

        results_data = {
            "meta": {
                "video_name": video_name,
                "fps": fps,
                "total_frames": total_frames,
                "resolution": [width, height]
            },
            "frames": []
        }

        # YOLO ì¶”ë¡  (stream=Trueë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”)
        # RTX 5060 Tiì˜ ê²½ìš° device=0 ëª…ì‹œ
        results = self.model.predict(source=video_path, stream=True, device=self.device, verbose=False)

        for i, result in enumerate(results):
            frame_data = {
                "frame_id": i,
                "keypoints": []
            }

            # ì‚¬ëŒì´ ê°ì§€ëœ ê²½ìš°
            if result.keypoints is not None:
                # ì²« ë²ˆì§¸ ì‚¬ëŒ(ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì‚¬ëŒ)ë§Œ ì¶”ì¶œ
                # data[0]ì€ (N, 3) í˜•íƒœ: [x, y, confidence]
                keypoints = result.keypoints.data[0].cpu().numpy().tolist()
                frame_data["keypoints"] = keypoints
            
            results_data["frames"].append(frame_data)
            
            # ì§„í–‰ ìƒí™© ë¡œê¹… (100 í”„ë ˆì„ë§ˆë‹¤)
            if i % 100 == 0:
                print(f"   â³ ì²˜ë¦¬ ì¤‘... {i}/{total_frames} frames")

        cap.release()

        # JSON ì €ì¥
        with open(output_json_path, 'w') as f:
            json.dump(results_data, f)
        
        print(f"âœ… [AI] ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨: {output_json_path}")
        return output_json_path

# í…ŒìŠ¤íŠ¸ìš© (ì´ íŒŒì¼ë§Œ ì§ì ‘ ì‹¤í–‰í–ˆì„ ë•Œ)
if __name__ == "__main__":
    estimator = PoseEstimator()
    # í…ŒìŠ¤íŠ¸ ì˜ìƒ ê²½ë¡œë¥¼ ì§ì ‘ ì§€ì •í•´ì„œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
    # estimator.process_video("data/raw_videos/test.mp4", "data/results")
