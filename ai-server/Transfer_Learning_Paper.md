# 전이 학습 과정 분석

## 1. 문제 발생

---

전체 파라미터를 파인튜닝 했더니, 사람이 어디에 있는지 찾지 못하고 사람을 찾더라도 관절의 위치를 제대로 추출하지 못하는 문제가 발생했다.

학습에 사용한 안무 영상은 사람 크기와 배경 등이 일관된 영상이라서, 이러한 데이터셋으로 백본 네트워크를 학습시키면 사람의 특징보다 배경 및 사람의 크기를 학습해버릴 위험이 있다.

COCO 데이터셋으로 학습된 다양한 사람 형태에 대한 가중치가 위의 데이터셋으로 파인튜닝될 경우 파괴된다.

## 2. 해결 방법

---

YOLO 모델은 Backbone, Neck, Head로 구성된다. 이 중 HEAD만 파인튜닝을 하면 위의 문제를 해결할 수 있다고 가정한다.

## 3. 구체적인 방법

---

YOLO 모델의 Backbone과 Neck이 어디 부분인지 파악한다.

YOLO 모델의 Backbone과 Neck을 Freeze해야 한다. 만약 이럼에도 파인튜닝이 잘 안된다면 Backbone만 Freeze 하는 것을 고려할 수 있다.

학습률은 낮은 값으로 시작한다. 0.001이나 0.0005인 낮은 값으로 시작한다.

초반의 급격한 가중치 변화를 방지하기 위해 Warmup 전략을 사용한다.

데이터 증강을 할 때 초반에 Mosaic을 켜고, 후반에 Mosaic을 끈다. 그리고 Rotation과 Flip 증강도 수행한다.

## 4. 안무 데이터셋을 YOLO에 적합하도록 변경

---

prepare_data.py는 AI_HUB에서 다운 받은 NIA 안무 데이터 포멧 (29 Keypoint)을 COCO (17 Keypoint)에 맞추는 파일이다.

YOLO는 0 ~ 4 인덱스를 얼굴로 사용하는데, AI_HUB 데이터의 24 ~ 28 인덱스와 매칭한다.

| 부위 | AI_HUB (Source) | YOLO 인덱스 (Target) | 검증 |
| :--- | :---: | :---: | :---: |
| 코 (Nose) | 24 | 0 | 일치 |
| 왼쪽 눈 (L-Eye) | 25 | 1 | 일치 |
| 오른쪽 눈 (R-Eye) | 26 | 2 | 일치 |
| 왼쪽 귀 (L-Ear) | 27 | 3 | 일치 |
| 오른쪽 귀 (R-Ear) | 28 | 4 | 일치 |
| 왼쪽 어깨 (L-Shoulder) | 14 | 5 | 일치 |
| 오른쪽 어깨 (R-Shoulder) | 19 | 6 | 일치 |
| 왼쪽 팔꿈치 (L-Elbow) | 15 | 7 | 일치 |
| 오른쪽 팔꿈치 (R-Elbow) | 20 | 8 | 일치 |
| 왼쪽 손목 (L-Wrist) | 16 | 9 | 일치 |
| 오른쪽 손목 (R-Wrist) | 21 | 10 | 일치 |
| 왼쪽 골반 (L-Hip) | 1 | 11 | 일치 |
| 오른쪽 골반 (R-Hip) | 6 | 12 | 일치 |
| 왼쪽 무릎 (L-Knee) | 2 | 13 | 일치 |
| 오른쪽 무릎 (R-Knee) | 7 | 14 | 일치 |
| 왼쪽 발목 (L-Ankle) | 3 | 15 | 일치 |
| 오른쪽 발목 (R-Ankle) | 8 | 16 | 일치 |

### 가려짐 데이터 처리

---

YOLO에서 사용하는 Visibility Flag가 2이면 Key Point가 이미지 내에 있고 명확하다는 뜻이고, 1이면 이미지 내에 있지만 다른 신체 부위에 가려져 보이지 않는다는 뜻이고, 0이면 Key Point가 이미지 밖에 있거나 라벨리 되지 않는다는 뜻이다.

YOLO는 가려짐이 없는 데이터에서 Loss를 강하게 계산하고 가려짐이 1이면 약하게, 0이면 무시한다.

AI_HUB에도 이러한 값이 있는데 2와 1만 있고 0은 없다. 이를 가져와서 사용한다.

