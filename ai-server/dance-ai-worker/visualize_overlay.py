# >> visualize_overlay.py
# >> Source ì˜ìƒê³¼ User ì˜ìƒì— ê°ê° ìì‹ ì˜ ìŠ¤ì¼ˆë ˆí†¤ ë°ì´í„°ë¥¼ ì˜¤ë²„ë ˆì´í•˜ì—¬
# >> 2ê°œì˜ ë…ë¦½ì ì¸ ê²€ì¦ ì˜ìƒ(overlay_source.mp4, overlay_user.mp4)ì„ ìƒì„±í•©ë‹ˆë‹¤.

import cv2
import json
import os
import numpy as np

def run_overlay_visualization():
    # 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
    base_dir = os.path.dirname(os.path.abspath(__file__))
    sample_dir = os.path.join(base_dir, 'sampleMP4')
    result_dir = os.path.join(base_dir, 'calibration_result')
    
    # ì˜ìƒ íŒŒì¼ ê²½ë¡œ
    source_video_path = os.path.join(sample_dir, 'Cut_AfterLike_source.mp4')
    user_video_path = os.path.join(sample_dir, 'Cut_AfterLike_user.mp4')
    
    # JSON íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
    # 1) Source Expert JSON
    source_json_path = os.path.join(result_dir, "source_expert.json")
    
    # 2) User JSON (ê°€ì¥ ìµœì‹  íŒŒì¼)
    user_json_files = [f for f in os.listdir(result_dir) if "user" in f and f.endswith(".json") and "ID" in f]
    if not user_json_files:
        print("[Error] User JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    user_json_name = max(user_json_files, key=lambda f: os.path.getmtime(os.path.join(result_dir, f)))
    user_json_path = os.path.join(result_dir, user_json_name)

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    output_source = os.path.join(result_dir, "overlay_source_check.mp4")
    output_user = os.path.join(result_dir, "overlay_user_check.mp4")

    print(f"--- [ ê°œë³„ ì‹œê°í™” ê²€ì¦ ì‹œì‘ ] ---")
    
    # 2. ì˜ìƒ ìƒì„± ì‹¤í–‰
    # (1) Source ì˜ìƒ ìƒì„± (íŒŒë‘/ë…¸ë‘ í…Œë§ˆ)
    if os.path.exists(source_video_path) and os.path.exists(source_json_path):
        print(f"\n[1/2] Source ì˜ìƒ ì²˜ë¦¬ ì¤‘... ({os.path.basename(source_video_path)})")
        _create_single_overlay(
            source_video_path, 
            source_json_path, 
            output_source,
            bone_color=(0, 255, 255),  # Yellow
            joint_color=(255, 0, 0),   # Blue
            label="Expert (Source)"
        )
    else:
        print(f"[Skip] Source ì˜ìƒ ë˜ëŠ” JSONì´ ì—†ìŠµë‹ˆë‹¤.")

    # (2) User ì˜ìƒ ìƒì„± (ì´ˆë¡/ë¹¨ê°• í…Œë§ˆ)
    if os.path.exists(user_video_path) and os.path.exists(user_json_path):
        print(f"\n[2/2] User ì˜ìƒ ì²˜ë¦¬ ì¤‘... ({os.path.basename(user_video_path)})")
        _create_single_overlay(
            user_video_path, 
            user_json_path, 
            output_user,
            bone_color=(0, 255, 0),    # Green
            joint_color=(0, 0, 255),   # Red
            label="User (You)"
        )
    else:
        print(f"[Skip] User ì˜ìƒ ë˜ëŠ” JSONì´ ì—†ìŠµë‹ˆë‹¤.")

    print(f"\n--- [ ëª¨ë“  ì‘ì—… ì™„ë£Œ ] ---")
    print(f"1. {output_source}")
    print(f"2. {output_user}")
    print("ğŸ‘‰ ê° ì˜ìƒì„ í™•ì¸í•˜ì—¬ ë¼ˆëŒ€ê°€ ì‚¬ëŒ ëª¸ì— ì •í™•íˆ ë¶™ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

def _create_single_overlay(video_path, json_path, output_path, bone_color, joint_color, label):
    # ë°ì´í„° ë¡œë“œ
    with open(json_path, 'r') as f:
        pose_data = json.load(f)
    
    cap = cv2.VideoCapture(video_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    # ê´€ì ˆ ì—°ê²°
    connections = [
        (0,1), (0,2), (1,3), (2,4), 
        (5,6), (5,7), (7,9), (6,8), (8,10), 
        (5,11), (6,12), (11,12), 
        (11,13), (13,15), (12,14), (14,16)
    ]

    frames_data = pose_data['frames']
    frame_idx = 0
    
    while True:
        ret, frame = cap.read()
        if not ret: break
        
        # Draw Skeleton
        if frame_idx < len(frames_data):
            f_data = frames_data[frame_idx]
            if f_data['is_valid']:
                # ì •ê·œí™” ê¸°ì¤€ (pose_estimation.py ë¡œì§ ì—­ì‚°)
                max_dim = max(width, height)
                
                points = {}
                # Joints
                for i, (nx, ny, conf) in enumerate(f_data['keypoints']):
                    if conf > 0.3:
                        px = int(nx * max_dim)
                        py = int(ny * max_dim)
                        # Clipping
                        px = max(0, min(width - 1, px))
                        py = max(0, min(height - 1, py))
                        
                        points[i] = (px, py)
                        cv2.circle(frame, (px, py), 4, joint_color, -1)
                
                # Bones
                for u, v in connections:
                    if u in points and v in points:
                        cv2.line(frame, points[u], points[v], bone_color, 2)
        
        # Label
        cv2.putText(frame, f"{label} | Frame: {frame_idx}", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, bone_color, 2)
        
        out.write(frame)
        if frame_idx % 100 == 0:
            print(f"   >> {frame_idx}/{total_frames} frames...")
        frame_idx += 1

    cap.release()
    out.release()
    print(f"   âœ… ì €ì¥ ì™„ë£Œ: {output_path}")

if __name__ == "__main__":
    run_overlay_visualization()
