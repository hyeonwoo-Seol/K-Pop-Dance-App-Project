import cv2
import json
import os
import torch
import numpy as np
from ultralytics import YOLO

class PoseEstimator:
    def __init__(self, model_path='yolo11l-pose.pt'):
        """
        YOLO ëª¨ë¸ ì´ˆê¸°í™” ë° ì›Œë°ì—…
        :param model_path: ì‚¬ìš©í•  YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: Large ëª¨ë¸)
        """
        print(f"\nğŸ”„ [AI] YOLO ëª¨ë¸ ë¡œë”© ì¤‘... ({model_path})")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"âš¡ [AI] ì‹¤í–‰ ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ë¡œë“œ
        try:
            self.model = YOLO(model_path)
            print("âœ… [AI] ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ [Error] ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e

        # ì›Œë°ì—… ì‹¤í–‰ (ì²« ì‹¤í–‰ ë ‰ ë°©ì§€)
        self.warmup()

    def warmup(self):
        """
        ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì˜ˆì—´(Warm-up)í•˜ê³  VRAM ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤.
        """
        print("ğŸ”¥ [AI] ëª¨ë¸ ì›Œë°ì—… ì‹œì‘ (Dummy Inference)...")
        try:
            # 1. ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (YOLO ì…ë ¥ í¬ê¸°ì¸ 640x640, ê²€ì€ í™”ë©´)
            dummy_frame = np.zeros((640, 640, 3), dtype=np.uint8)
            
            # 2. ì¶”ë¡  ì‹¤í–‰ (ê²°ê³¼ëŠ” ë²„ë¦¼)
            # verbose=Falseë¡œ ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì¶œë ¥ ë°©ì§€
            self.model.predict(source=dummy_frame, device=self.device, verbose=False)
            
            print("ğŸ”¥ [AI] ëª¨ë¸ ì›Œë°ì—… ì™„ë£Œ! (Ready to serve)")

            # 3. VRAM ì ìœ ìœ¨ í™•ì¸ (ìš´ì˜ ìš©ëŸ‰ ì‚°ì •ìš©)
            if self.device == 'cuda':
                # í˜„ì¬ í• ë‹¹ëœ ë©”ëª¨ë¦¬ (Byte -> MB ë³€í™˜)
                allocated_bytes = torch.cuda.memory_allocated()
                allocated_mb = allocated_bytes / 1024 / 1024
                
                # ìµœëŒ€ ì˜ˆì•½ëœ ë©”ëª¨ë¦¬ (ìºì‹œ í¬í•¨)
                reserved_bytes = torch.cuda.memory_reserved()
                reserved_mb = reserved_bytes / 1024 / 1024

                print(f"ğŸ“Š [GPU Status] í˜„ì¬ ëª¨ë¸ VRAM ì ìœ : {allocated_mb:.2f} MB")
                print(f"ğŸ“Š [GPU Status] ì „ì²´ ì˜ˆì•½ëœ VRAM(ìºì‹œí¬í•¨): {reserved_mb:.2f} MB")
                
                # 16GB(ì•½ 16384MB) ê¸°ì¤€ ì‚¬ìš©ë¥  ê³„ì‚°
                usage_percent = (reserved_mb / 16384) * 100
                print(f"   (ì°¸ê³ : RTX 5060 Ti 16GB ê¸°ì¤€ ì•½ {usage_percent:.2f}% ì‚¬ìš© ì¤‘)")
                
        except Exception as e:
            print(f"âš ï¸ [Warning] ì›Œë°ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

    def process_video(self, video_path, output_dir):
        """
        ì˜ìƒì„ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ì—¬ ìŠ¤ì¼ˆë ˆí†¤ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        """
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        video_name = os.path.splitext(os.path.basename(video_path))[0]
        output_json_path = os.path.join(output_dir, f"{video_name}_analysis.json")
        
        # ì˜ìƒ ì •ë³´ ì½ê¸°
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"ğŸ¬ [AI] ë¶„ì„ ì‹œì‘: {video_name} (FPS: {fps}, Frames: {total_frames})")

        results_data = {
            "meta": {
                "video_name": video_name,
                "fps": fps,
                "total_frames": total_frames,
                "resolution": [width, height],
                "model": "yolo11l-pose"
            },
            "frames": []
        }

        # YOLO ì¶”ë¡  (stream=Trueë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”)
        results = self.model.predict(source=video_path, stream=True, device=self.device, verbose=False)

        for i, result in enumerate(results):
            frame_data = {
                "frame_id": i,
                "keypoints": []
            }

            # ì‚¬ëŒì´ ê°ì§€ëœ ê²½ìš°
            if result.keypoints is not None:
                # ì²« ë²ˆì§¸ ì‚¬ëŒ(ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì‚¬ëŒ)ë§Œ ì¶”ì¶œ
                # data[0]ì€ (N, 3) í˜•íƒœ: [x, y, confidence]
                if len(result.keypoints.data) > 0:
                    keypoints = result.keypoints.data[0].cpu().numpy().tolist()
                    frame_data["keypoints"] = keypoints
            
            results_data["frames"].append(frame_data)
            
            # ì§„í–‰ ìƒí™© ë¡œê¹… (100 í”„ë ˆì„ë§ˆë‹¤)
            if i % 100 == 0:
                print(f"   â³ ì²˜ë¦¬ ì¤‘... {i}/{total_frames} frames")

        cap.release()

        # JSON ì €ì¥
        with open(output_json_path, 'w') as f:
            json.dump(results_data, f)
        
        print(f"âœ… [AI] ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ ì €ì¥ë¨: {output_json_path}")
        return output_json_path

# í…ŒìŠ¤íŠ¸ìš© (ì´ íŒŒì¼ë§Œ ì§ì ‘ ì‹¤í–‰í–ˆì„ ë•Œ)
if __name__ == "__main__":
    # í´ë˜ìŠ¤ ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ì›Œë°ì—…ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    estimator = PoseEstimator()
    
    # VRAM ë¡œê·¸ë¥¼ í™•ì¸í•œ í›„, ì‹¤ì œ ì˜ìƒ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.
    # estimator.process_video("data/raw_videos/test.mp4", "data/results")
